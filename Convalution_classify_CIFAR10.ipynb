{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convalution_classify_CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David 9回顾去年著名论文All you need is a good init，当时提出了一种新型初始化权重的方法，号称在Cifar-10上达到94.16%的精度，这里用keras还原一下试试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运用tensorflow和高级api——keras，构建一个卷积神经网络模型。应用到数据集CIFAR10，作图片类别识别任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先导入需要的包，包括常用数据处理和图表显示模块。  \n",
    "需要下载初始化权重的包：git clone https://github.com/ducha-aiki/LSUV-keras  \n",
    "可惜这个包里面有错误，需要略微修改。  \n",
    "66至68行替换为如下代码：  \n",
    "```\n",
    "layer.set_weights(weights_and_biases)\n",
    "weights_and_biases[1] /= np.sqrt(variance) / np.sqrt(needed_variance)\n",
    "layer.set_weights(weights_and_biases)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras\n",
    "from tensorflow.compat.v1.keras import layers,datasets,utils,models\n",
    "from tensorflow.compat.v1.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalMaxPooling2D \n",
    "import numpy as np\n",
    "from tensorflow.compat.v1.keras.utils import to_categorical\n",
    "from lsuv_init import LSUVinit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)                   \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设定一下batch大小，类别数，训练轮数，还有就是启用数据增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用的是keras内置加载数据。  \n",
    "由于数据源是国外多伦多大学网站，这一步要事先下载好放到指定位置：  \n",
    "windows：user/.keras/datasets/  \n",
    "linux：~/.keras/datasets/  \n",
    "并且对压缩包改名：  \n",
    "cifar-10-python.tar.gz -> cifar-10-batch.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据归一化、独热编码化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个15层的CNN神经网络，具体结构很容易看明白。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(48, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(48, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(80, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一块没有特殊的地方，常规的损失函数定义和模型编译。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.SGD(lr=0.0001)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论文的重点特色就在于此，使用特殊的初始化方法，得以提升性能。  \n",
    "第二行不重要，是监控。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "LSUV initializing conv2d\n",
      "0.0176714\n",
      "0.99999976\n",
      "activation\n",
      "conv2d_1\n",
      "LSUV initializing conv2d_1\n",
      "0.045270506\n",
      "1.0\n",
      "activation_1\n",
      "conv2d_2\n",
      "LSUV initializing conv2d_2\n",
      "0.0128124105\n",
      "0.9999999\n",
      "activation_2\n",
      "conv2d_3\n",
      "LSUV initializing conv2d_3\n",
      "0.034055423\n",
      "0.9999998\n",
      "activation_3\n",
      "conv2d_4\n",
      "LSUV initializing conv2d_4\n",
      "0.03496846\n",
      "1.0000001\n",
      "activation_4\n",
      "max_pooling2d\n",
      "dropout\n",
      "conv2d_5\n",
      "LSUV initializing conv2d_5\n",
      "0.031640578\n",
      "0.9999998\n",
      "activation_5\n",
      "conv2d_6\n",
      "LSUV initializing conv2d_6\n",
      "0.01377221\n",
      "0.9999999\n",
      "activation_6\n",
      "conv2d_7\n",
      "LSUV initializing conv2d_7\n",
      "0.023633204\n",
      "0.9999999\n",
      "activation_7\n",
      "conv2d_8\n",
      "LSUV initializing conv2d_8\n",
      "0.015010685\n",
      "0.9999998\n",
      "activation_8\n",
      "conv2d_9\n",
      "LSUV initializing conv2d_9\n",
      "0.015397631\n",
      "1.0000001\n",
      "activation_9\n",
      "max_pooling2d_1\n",
      "dropout_1\n",
      "conv2d_10\n",
      "LSUV initializing conv2d_10\n",
      "0.012721574\n",
      "1.0000001\n",
      "activation_10\n",
      "conv2d_11\n",
      "LSUV initializing conv2d_11\n",
      "0.009487288\n",
      "0.9999999\n",
      "activation_11\n",
      "conv2d_12\n",
      "LSUV initializing conv2d_12\n",
      "0.010537763\n",
      "1.0\n",
      "activation_12\n",
      "conv2d_13\n",
      "LSUV initializing conv2d_13\n",
      "0.012298666\n",
      "1.0\n",
      "activation_13\n",
      "conv2d_14\n",
      "LSUV initializing conv2d_14\n",
      "0.008218203\n",
      "1.0000001\n",
      "activation_14\n",
      "global_max_pooling2d\n",
      "dropout_2\n",
      "dense\n",
      "LSUV initializing dense\n",
      "0.6945075\n",
      "0.99999994\n",
      "activation_15\n",
      "dropout_3\n",
      "dense_1\n",
      "dense_1 too small\n",
      "activation_16\n",
      "LSUV: total layers initialized 16\n"
     ]
    }
   ],
   "source": [
    "model = LSUVinit(model,x_train[:batch_size,:,:,:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./model/initmethods_weigths.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='.\\\\Graph2', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强，属于图像处理的常规手段了。  \n",
    "可以选择不开启。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/5\n",
      "   1/3125 [..............................] - ETA: 1:02:05 - loss: 1.0924 - accuracy: 0.6250WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.141147). Check your callbacks.\n",
      "3125/3125 [==============================] - 168s 54ms/step - loss: 1.2419 - accuracy: 0.5519 - val_loss: 1.2221 - val_accuracy: 0.5564\n",
      "Epoch 2/5\n",
      "3125/3125 [==============================] - 169s 54ms/step - loss: 1.2422 - accuracy: 0.5535 - val_loss: 1.2279 - val_accuracy: 0.5547\n",
      "Epoch 3/5\n",
      "3125/3125 [==============================] - 172s 55ms/step - loss: 1.2377 - accuracy: 0.5530 - val_loss: 1.2127 - val_accuracy: 0.5596\n",
      "Epoch 4/5\n",
      "3125/3125 [==============================] - 165s 53ms/step - loss: 1.2423 - accuracy: 0.5528 - val_loss: 1.2088 - val_accuracy: 0.5613\n",
      "Epoch 5/5\n",
      "3125/3125 [==============================] - 171s 55ms/step - loss: 1.2335 - accuracy: 0.5543 - val_loss: 1.2195 - val_accuracy: 0.5570\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True, callbacks=[tbCallBack])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test), callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\tf3.6\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: CIFAR10_conv_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('CIFAR10_conv_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model/initmethods_weigths.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6584567c686d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./weigths.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.load_weights('./weigths.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf3.6]",
   "language": "python",
   "name": "conda-env-tf3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
